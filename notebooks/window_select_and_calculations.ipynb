{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "import qa_functions as qa\n",
                "from tqdm import tqdm\n",
                "import temperature_data_fns as td\n",
                "\n",
                "pd.set_option(\"display.max_columns\", None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set file format of cleaned data you have, either parquet or csv\n",
                "# If you have run the clean.ipynb file to generate the cleaned data, they will be in parquet\n",
                "file_format = qa.set_file_format(file_format=\"parquet\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Specify which folder contains your local directory\n",
                "eoh_folder = os.environ.get(\"EoH\")\n",
                "\n",
                "# Specify location of specific folders\n",
                "location = os.path.join(eoh_folder)\n",
                "location_out = os.path.join(location, \"processed\")\n",
                "location_out_cleaned = os.path.join(location_out, \"cleaned\")\n",
                "\n",
                "# Generate a list of all files to be run through the code\n",
                "files_info=[]\n",
                "\n",
                "for home in os.listdir(os.path.join(location_out_cleaned, \"cleaned\")):\n",
                "    size = os.stat(os.path.join(location_out_cleaned, \"cleaned\", home))[6]\n",
                "    file_info = [home, round(size/1024)]\n",
                "    files_info.append(file_info)\n",
                "# Remove properties which do not have more than 1KB of data\n",
                "files_info = pd.DataFrame(files_info, columns=[\"Property_Name\", \"Size_KB\"])\n",
                "files_info = files_info[files_info[\"Size_KB\"] > 1]\n",
                "files_list = list(files_info.iloc[:, 0])\n",
                "files_list = [file[0:7] for file in files_list]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the boundaries for the ranges of gap length\n",
                "# duration < short - Not a gap\n",
                "# short < duration < medium - a short gap\n",
                "# medium < duration < long - a medium gap\n",
                "# duration > long - a long gap\n",
                "gap_len_defs = {\n",
                "    \"long\": pd.Timedelta(days=21),\n",
                "    \"medium\": pd.Timedelta(days=7),\n",
                "    \"short\": pd.Timedelta(minutes=30),\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the performance factor ranges for different time scales\n",
                "# For short time scales, we expect higher variation in the performance factor\n",
                "# short time periods are around a day, long are around a year, medium is in between these two\n",
                "spf_ranges = {\n",
                "    \"short\": {\"min\": 0.75, \"max\": 7.5},\n",
                "    \"medium\": {\"min\": 0.9, \"max\": 6.5},\n",
                "    \"long\": {\"min\": 1.5, \"max\": 5.0},\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "window_method = \"best\"\n",
                "save_scored_data = True\n",
                "plotting = True\n",
                "all_windows = pd.DataFrame()\n",
                "home_summary = []\n",
                "all_homes_alteration_record = pd.DataFrame()\n",
                "home_summary_cleaned = pd.read_csv(os.path.join(location, \"processed\", \"home_summary_partial_1.csv\"))\n",
                "for i, home in zip(tqdm(range(len(files_list))), files_list):\n",
                "    id = home\n",
                "    if plotting:\n",
                "        # Un-comment to save the plots\n",
                "        plot_full_save_path = os.path.join(location_out_cleaned, \"plots\", \"full\", home + \".png\")\n",
                "        plot_window_save_path = os.path.join(location_out_cleaned, \"plots\", \"window\", home + \".png\")\n",
                "        # Un-comment for fig.show()\n",
                "        # plot_full_save_path = \"none\"\n",
                "        # plot_window_save_path = \"none\"\n",
                "    else:\n",
                "        plot_full_save_path = \"\"\n",
                "        plot_window_save_path = \"\"\n",
                "\n",
                "    if file_format == \"csv\":\n",
                "        data = pd.read_csv(os.path.join(location_out_cleaned, \"cleaned\", home)).set_index(\"Timestamp\")\n",
                "        data[\"sensor_type\"] = data[\"sensor_type\"].str.lower()\n",
                "    elif file_format == \"parquet\":\n",
                "        data = pd.read_parquet(os.path.join(location_out_cleaned, \"cleaned\", f\"{home}.parquet\")).set_index(\"Timestamp\")\n",
                "\n",
                "    # Rename heat pump energy consumed to whole system energy consumed in case it is incorrectly labelled in the raw data\n",
                "    data[\"sensor_type\"] = data[\"sensor_type\"].replace({\"Heat_Pump_Energy_Consumed\": \"Whole_System_Energy_Consumed\"})\n",
                "\n",
                "    home_summary_part = home_summary_cleaned[home_summary_cleaned[\"Property_ID\"] == id]\n",
                "\n",
                "    # Select the best window for this data, this function also adds stats about the window to the output\n",
                "    (window_data, home_summary_part, cleaned_data, windows, single_home_alteration_record,) = qa.select_window(\n",
                "        data,\n",
                "        gap_len_defs,\n",
                "        home_summary_part,\n",
                "        spf_ranges=spf_ranges,\n",
                "        window_len_mths=12,\n",
                "        method=window_method,\n",
                "        plot_full_save_path=plot_full_save_path,\n",
                "        plot_window_save_path=plot_window_save_path,\n",
                "        location_out_cleaned=location_out_cleaned,\n",
                "        file=home,\n",
                "        save_scored_data=save_scored_data,\n",
                "    )\n",
                "\n",
                "    # Add most common flow temperatures to home_summary\n",
                "    file_path = os.path.join(location_out, \"binned_heating_temperature\", home + \".csv\")\n",
                "    plot_path = os.path.join(location_out, \"binned_heating_temperature\", \"plots\", home + \".png\")\n",
                "\n",
                "    # We only want to add these stats if a window exists\n",
                "    if \"window_start\" in home_summary_part.columns:\n",
                "        home_summary_part = td.add_flow_temp_stats_for_window(\n",
                "            data, home_summary_part, id, file_path=file_path, plot_path=plot_path\n",
                "        )\n",
                "\n",
                "    # Find spfs for coldest day\n",
                "    home_summary_part_cold_day = td.add_spfs_for_coldest_period(data, id, pd.Timedelta(days=1), \"Coldest_day_\")\n",
                "\n",
                "    # Find spfs for coldest half-hour\n",
                "    home_summary_part_cold_HH = td.add_spfs_for_coldest_period(data, id, pd.Timedelta(minutes=30), \"Coldest_HH_\")\n",
                "\n",
                "    if (len(home_summary_part_cold_day) > 0) & (len(home_summary_part_cold_HH) > 0):\n",
                "        home_summary_part_cold = pd.merge(\n",
                "            home_summary_part_cold_day,\n",
                "            home_summary_part_cold_HH,\n",
                "            on=\"Property_ID\",\n",
                "            how=\"outer\",\n",
                "        )\n",
                "\n",
                "        home_summary_part = home_summary_part.merge(home_summary_part_cold, on=\"Property_ID\")\n",
                "\n",
                "    home_summary_part[\"window_method\"] = window_method\n",
                "    home_summary.append(home_summary_part)\n",
                "\n",
                "    # We want to save all the possible windows out separately to do some analysis on them\n",
                "    windows[\"Property_ID\"] = home\n",
                "    all_windows = pd.concat([all_windows, windows], axis=0)\n",
                "\n",
                "    # We want to keep all the alteration records for all homes\n",
                "    if len(single_home_alteration_record) > 0:\n",
                "        single_home_alteration_record[\"Property_ID\"] = id\n",
                "    all_homes_alteration_record = pd.concat([all_homes_alteration_record, single_home_alteration_record])\n",
                "\n",
                "home_summary = pd.concat(home_summary)\n",
                "\n",
                "cleaning_flags = pd.read_csv(os.path.join(location_out, \"temperature_stats_with_outcome.csv\"))\n",
                "cleaning_flags = (\n",
                "    cleaning_flags.groupby(\"Property_ID\")\n",
                "    .max()[[\"issue\", \"outcome\", \"anomalies cleaned\", \"HWFT partial swap\", \"HWFT full swap\"]]\n",
                "    .add_prefix(\"temperature_cleaning_\")\n",
                "    .reset_index()\n",
                ")\n",
                "cleaning_flags[\"Property_ID\"] = cleaning_flags[\"Property_ID\"].astype(str)\n",
                "\n",
                "home_summary = pd.merge(home_summary, cleaning_flags, on=\"Property_ID\")\n",
                "\n",
                "home_summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# If running the whole set of homes, we want to over-write the old file\n",
                "home_summary.to_csv(os.path.join(location_out, \"home_summary.csv\"), index=False)\n",
                "home_summary.to_csv(os.path.join(location_out, \"home_summary.csv\"), index=False)\n",
                "\n",
                "# save out all the windows data to file\n",
                "all_windows.to_csv(os.path.join(location_out, \"all_windows.csv\"), index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We save a redacted version of the home summary file to allow a quick comparison to the output of previous code versions\n",
                "home_summary_partial_2 = home_summary[\n",
                "    [\n",
                "        \"Property_ID\",\n",
                "        \"Whole_start\",\n",
                "        \"Whole_end\",\n",
                "        \"Whole_duration_days\",\n",
                "        \"Whole_%_complete_Circulation_Pump_Energy_Consumed\",\n",
                "        \"Whole_%_complete_Whole_System_Energy_Consumed\",\n",
                "        \"Whole_%_complete_Heat_Pump_Energy_Output\",\n",
                "        \"Whole_%_complete_Immersion_Heater_Energy_Consumed\",\n",
                "        \"Cleaned_start\",\n",
                "        \"Cleaned_end\",\n",
                "        \"Cleaned_duration_days\",\n",
                "        \"Cleaned_%_complete_Circulation_Pump_Energy_Consumed\",\n",
                "        \"Cleaned_%_complete_Whole_System_Energy_Consumed\",\n",
                "        \"Cleaned_%_complete_Heat_Pump_Energy_Output\",\n",
                "        \"Cleaned_%_complete_Immersion_Heater_Energy_Consumed\",\n",
                "        \"acceptable windows: spfh2: count\",\n",
                "        \"acceptable windows: spfh2: mean\",\n",
                "        \"acceptable windows: spfh2: std\",\n",
                "        \"acceptable windows: spfh2: min\",\n",
                "        \"acceptable windows: spfh2: 25%\",\n",
                "        \"acceptable windows: spfh2: 50%\",\n",
                "        \"acceptable windows: spfh2: 75%\",\n",
                "        \"acceptable windows: spfh2: max\",\n",
                "        \"acceptable windows: spfh3: count\",\n",
                "        \"acceptable windows: spfh3: mean\",\n",
                "        \"acceptable windows: spfh3: std\",\n",
                "        \"acceptable windows: spfh3: min\",\n",
                "        \"acceptable windows: spfh3: 25%\",\n",
                "        \"acceptable windows: spfh3: 50%\",\n",
                "        \"acceptable windows: spfh3: 75%\",\n",
                "        \"acceptable windows: spfh3: max\",\n",
                "        \"acceptable windows: spfh4: count\",\n",
                "        \"acceptable windows: spfh4: mean\",\n",
                "        \"acceptable windows: spfh4: std\",\n",
                "        \"acceptable windows: spfh4: min\",\n",
                "        \"acceptable windows: spfh4: 25%\",\n",
                "        \"acceptable windows: spfh4: 50%\",\n",
                "        \"acceptable windows: spfh4: 75%\",\n",
                "        \"acceptable windows: spfh4: max\",\n",
                "        \"window_start\",\n",
                "        \"window_end\",\n",
                "        \"window_max_gap_score\",\n",
                "        \"window_max_data_score\",\n",
                "        \"window_max_score\",\n",
                "        \"window_mean_gap_score\",\n",
                "        \"window_mean_data_score\",\n",
                "        \"window_mean_score\",\n",
                "        \"window_Circulation_Pump_Energy_Consumed\",\n",
                "        \"window_Whole_System_Energy_Consumed\",\n",
                "        \"window_Heat_Pump_Energy_Output\",\n",
                "        \"window_Immersion_Heater_Energy_Consumed\",\n",
                "        \"window_Back-up_Heater_Energy_Consumed\",\n",
                "        \"window_Boiler_Energy_Output\",\n",
                "        \"spfh2\",\n",
                "        \"spfh3\",\n",
                "        \"spfh4\",\n",
                "        \"window_duration_days\",\n",
                "        \"window_%_complete_Circulation_Pump_Energy_Consumed\",\n",
                "        \"window_%_complete_Whole_System_Energy_Consumed\",\n",
                "        \"window_%_complete_Heat_Pump_Energy_Output\",\n",
                "        \"window_%_complete_Immersion_Heater_Energy_Consumed\",\n",
                "        \"window_method\",\n",
                "        \"Whole_%_complete_Boiler_Energy_Output\",\n",
                "        \"Cleaned_%_complete_Boiler_Energy_Output\",\n",
                "        \"window_%_complete_Boiler_Energy_Output\",\n",
                "        \"Whole_%_complete_Back-up_Heater_Energy_Consumed\",\n",
                "        \"Cleaned_%_complete_Back-up_Heater_Energy_Consumed\",\n",
                "        \"window_%_complete_Back-up_Heater_Energy_Consumed\",\n",
                "    ]\n",
                "]\n",
                "home_summary_partial_2.to_csv(os.path.join(location_out, \"home_summary_partial_2.csv\"), index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.8 64-bit (microsoft store)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.10"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "71944e760720e8245600bd84d984dcad76ef59e54d905ed8a60ff57ef0be5385"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
